{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "D1anb1ytuz2k"
      },
      "source": [
        "<a name=\"top\"> <h1>02. Neuronal Networks</h1> <a>\n",
        "\n",
        "<p>Análisis de sentimiento: Tweets<br />\n",
        "<strong>Trabajo de Fin de Master</strong><br />\n",
        "<strong>Master Universitario en Ciencia de Datos</strong></p>\n",
        "\n",
        "<p>&nbsp;</p>\n",
        "\n",
        "<p style=\"text-align:right\">V&iacute;ctor Viloria V&aacute;zquez (<em>victor.viloria@cunef.edu</em>)</p>\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MGnWP0EVuz2p"
      },
      "source": [
        "<hr style=\"border:1px solid gray\">"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "V-c-ExD8uz2y"
      },
      "source": [
        "### Estructura"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4y506okXuz22"
      },
      "source": [
        "[1. Librerias utilizadas y funciones](#librerias) \n",
        "\n",
        "[2. Introducción ](#introduccion) \n",
        "\n",
        "   - Objetivo de negocio.\n",
        "\n",
        "[3. Yelp Dataset ](#yelp) \n",
        "\n",
        "   - Información del dataset\n",
        "   - Características del dataset\n",
        "\n",
        "\n",
        "[4. Transformación del formato de ficheros](#transformacion) \n",
        "\n",
        "\n",
        "[5. Transformación de datos](#datos)\n",
        "\n",
        "   - Business\n",
        "       - Carga del fichero\n",
        "       - Transformación de los datos\n",
        "       - Exportación de ficheros procesados"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nhcT10vJuz24"
      },
      "source": [
        "<hr style=\"border:1px solid gray\">"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_mjKoACXuz25"
      },
      "source": [
        "# <a name=\"librerias\"> 1. Librerias utilizadas y funciones <a>\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9JBx12Gsuz26"
      },
      "source": [
        "Importamos las librerias a utilizar para el preprocesamiento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "a3eiEFg5uz3G"
      },
      "outputs": [],
      "source": [
        "# Import libraries.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "import numpy as np\n",
        "import string\n",
        "import pickle\n",
        "\n",
        "# Import neural network libraries.\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Dropout, Dense\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "from sklearn.metrics import fbeta_score\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "U3CG8-gbuz3I"
      },
      "source": [
        "# <a name=\"lectura\"> 2. Lectura del dataframe <a>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "PJBg5uE4uz3J",
        "outputId": "006f678f-715e-4a99-f8d6-1ce8fd18ae30"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>SentimentText_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id have responded if i were going</td>\n",
              "      <td>0</td>\n",
              "      <td>id responded going</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sooo sad i will miss you here in san diego</td>\n",
              "      <td>2</td>\n",
              "      <td>sooo sad miss san diego</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>my boss is bullying me</td>\n",
              "      <td>2</td>\n",
              "      <td>boss bullying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>what interview leave me alone</td>\n",
              "      <td>2</td>\n",
              "      <td>interview leave alone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sons of  why couldnt they put them on the rel...</td>\n",
              "      <td>2</td>\n",
              "      <td>sons couldnt put releases already bought</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>some shameless plugging for the best rangers...</td>\n",
              "      <td>0</td>\n",
              "      <td>shameless plugging best rangers forum earth</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2am feedings for the baby are fun when he is a...</td>\n",
              "      <td>1</td>\n",
              "      <td>2am feedings baby fun smiles coos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>soooo high</td>\n",
              "      <td>0</td>\n",
              "      <td>soooo high</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>both of you</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>journey wow u just became cooler  hehe is tha...</td>\n",
              "      <td>1</td>\n",
              "      <td>journey wow u became cooler hehe possible</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  sentiment  \\\n",
              "0                  id have responded if i were going          0   \n",
              "1         sooo sad i will miss you here in san diego          2   \n",
              "2                             my boss is bullying me          2   \n",
              "3                      what interview leave me alone          2   \n",
              "4   sons of  why couldnt they put them on the rel...          2   \n",
              "5    some shameless plugging for the best rangers...          0   \n",
              "6  2am feedings for the baby are fun when he is a...          1   \n",
              "7                                         soooo high          0   \n",
              "8                                        both of you          0   \n",
              "9   journey wow u just became cooler  hehe is tha...          1   \n",
              "\n",
              "                           SentimentText_clean  \n",
              "0                           id responded going  \n",
              "1                      sooo sad miss san diego  \n",
              "2                                boss bullying  \n",
              "3                        interview leave alone  \n",
              "4     sons couldnt put releases already bought  \n",
              "5  shameless plugging best rangers forum earth  \n",
              "6            2am feedings baby fun smiles coos  \n",
              "7                                   soooo high  \n",
              "8                                               \n",
              "9    journey wow u became cooler hehe possible  "
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Import parquet file.\n",
        "\n",
        "tweets_df = pd.read_parquet('../../data/processed/tweets.parquet')\n",
        "\n",
        "# Show the head of the dataframe.\n",
        "\n",
        "tweets_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Dw3Rbo2zzuOo"
      },
      "outputs": [],
      "source": [
        "# Save in tweets the column \"SentimentText_clean\" and in sentimientos the column \"sentiment\".   \n",
        "\n",
        "tweets = tweets_df[\"SentimentText_clean\"]\n",
        "\n",
        "sentimientos = tweets_df[\"sentiment\"].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62j40yWBxBY3",
        "outputId": "ea0323ab-5773-43e5-8b1a-9c144622f8a4"
      },
      "outputs": [],
      "source": [
        "# Dividir los datos en características y etiquetas\n",
        "X = tweets\n",
        "y = tweets_df['sentiment'].values\n",
        "y = tf.keras.utils.to_categorical(y)  # Convertir los valores numéricos a representación categórica (one-hot encoding)\n",
        "\n",
        "# División de datos en conjunto de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenización y secuenciación del texto\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# Ajuste de la longitud de las secuencias (padding)\n",
        "max_sequence_length = 100  # Longitud máxima de una secuencia de palabras\n",
        "X_train_seq = tf.keras.preprocessing.sequence.pad_sequences(X_train_seq, maxlen=max_sequence_length)\n",
        "X_test_seq = tf.keras.preprocessing.sequence.pad_sequences(X_test_seq, maxlen=max_sequence_length)\n",
        "\n",
        "# Creación del modelo de red neuronal\n",
        "model = models.Sequential()\n",
        "model.add(layers.Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100, input_length=max_sequence_length))\n",
        "model.add(layers.LSTM(64))\n",
        "model.add(layers.Dense(3, activation='softmax'))\n",
        "\n",
        "\n",
        "# Compilación del modelo\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "#model.fit(X_train_seq, y_train, validation_data=(X_test_seq, y_test), epochs=10, batch_size=32)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMQ0vxNjxBY5",
        "outputId": "a4a23d4e-fcfd-4411-eceb-a6e1727c477d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 203ms/step\n",
            "Sentimiento predicho: negativo\n"
          ]
        }
      ],
      "source": [
        "# Prueba con un texto a introducir\n",
        "text_to_predict = \"My friend is a the worst person in the world\"\n",
        "text_to_predict_seq = tokenizer.texts_to_sequences([text_to_predict])\n",
        "text_to_predict_seq = tf.keras.preprocessing.sequence.pad_sequences(text_to_predict_seq, maxlen=max_sequence_length)\n",
        "prediction = model.predict(text_to_predict_seq)\n",
        "sentiment_label = np.argmax(prediction)\n",
        "\n",
        "# Mapeo de la clase de sentimiento predicha a su etiqueta original (0: neutral, 1: positivo, 2: negativo)\n",
        "sentiment_labels = ['neutral', 'positivo', 'negativo']\n",
        "predicted_sentiment = sentiment_labels[sentiment_label]\n",
        "\n",
        "print(\"Sentimiento predicho:\", predicted_sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lh4fvQGrx4lz"
      },
      "outputs": [],
      "source": [
        "#model.save(\"../../models/nn_reviews.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "Sentimiento predicho: positivo\n"
          ]
        }
      ],
      "source": [
        "# Load the model.\n",
        "\n",
        "model = tf.keras.models.load_model('../../models/nn_tweets.h5', compile=False)\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Prueba con un texto a introducir\n",
        "text_to_predict = \"My friend is a great person\"\n",
        "text_to_predict_seq = tokenizer.texts_to_sequences([text_to_predict])\n",
        "text_to_predict_seq = tf.keras.preprocessing.sequence.pad_sequences(text_to_predict_seq, maxlen=max_sequence_length)\n",
        "prediction = model.predict(text_to_predict_seq)\n",
        "sentiment_label = np.argmax(prediction)\n",
        "\n",
        "# Mapeo de la clase de sentimiento predicha a su etiqueta original (0: neutral, 1: positivo, 2: negativo)\n",
        "sentiment_labels = ['neutral', 'positivo', 'negativo']\n",
        "predicted_sentiment = sentiment_labels[sentiment_label]\n",
        "\n",
        "print(\"Sentimiento predicho:\", predicted_sentiment)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "172/172 [==============================] - 6s 35ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.6525390206829367"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Predict x_test.\n",
        "\n",
        "y_pred = model.predict(X_test_seq)\n",
        "\n",
        "# Convert y_pred to 1D array.\n",
        "\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Convert y_test to 1D array.\n",
        "\n",
        "y_test = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Obtain the F2 score.\n",
        "\n",
        "# Print: F2 score.\n",
        "\n",
        "print(\"F2 score: \", fbeta_score(y_test, y_pred, beta=2, average='weighted'))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4MEOQW7xBY8"
      },
      "outputs": [],
      "source": [
        "model.save(\"../../models/nn_tweets.h5\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
