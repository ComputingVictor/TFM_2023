{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "D1anb1ytuz2k"
      },
      "source": [
        "<a name=\"top\"> <h1>02. Neuronal Networks</h1> <a>\n",
        "\n",
        "<p>Análisis de sentimiento: Tweets<br />\n",
        "<strong>Trabajo de Fin de Master</strong><br />\n",
        "<strong>Master Universitario en Ciencia de Datos</strong></p>\n",
        "\n",
        "<p>&nbsp;</p>\n",
        "\n",
        "<p style=\"text-align:right\">V&iacute;ctor Viloria V&aacute;zquez (<em>victor.viloria@cunef.edu</em>)</p>\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MGnWP0EVuz2p"
      },
      "source": [
        "<hr style=\"border:1px solid gray\">"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "V-c-ExD8uz2y"
      },
      "source": [
        "### Estructura"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4y506okXuz22"
      },
      "source": [
        "[1. Librerias utilizadas y funciones](#librerias) \n",
        "\n",
        "[2. Introducción ](#introduccion) \n",
        "\n",
        "   - Objetivo de negocio.\n",
        "\n",
        "[3. Yelp Dataset ](#yelp) \n",
        "\n",
        "   - Información del dataset\n",
        "   - Características del dataset\n",
        "\n",
        "\n",
        "[4. Transformación del formato de ficheros](#transformacion) \n",
        "\n",
        "\n",
        "[5. Transformación de datos](#datos)\n",
        "\n",
        "   - Business\n",
        "       - Carga del fichero\n",
        "       - Transformación de los datos\n",
        "       - Exportación de ficheros procesados"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nhcT10vJuz24"
      },
      "source": [
        "<hr style=\"border:1px solid gray\">"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_mjKoACXuz25"
      },
      "source": [
        "# <a name=\"librerias\"> 1. Librerias utilizadas y funciones <a>\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9JBx12Gsuz26"
      },
      "source": [
        "Importamos las librerias a utilizar para el preprocesamiento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "a3eiEFg5uz3G"
      },
      "outputs": [],
      "source": [
        "# Import libraries.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "import numpy as np\n",
        "import string\n",
        "import pickle\n",
        "\n",
        "# Import neural network libraries.\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Dropout, Dense\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "from sklearn.metrics import fbeta_score\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "U3CG8-gbuz3I"
      },
      "source": [
        "# <a name=\"lectura\"> 2. Lectura del dataframe <a>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "PJBg5uE4uz3J",
        "outputId": "006f678f-715e-4a99-f8d6-1ce8fd18ae30"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>SentimentText_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id have responded if i were going</td>\n",
              "      <td>0</td>\n",
              "      <td>id responded going</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sooo sad i will miss you here in san diego</td>\n",
              "      <td>2</td>\n",
              "      <td>sooo sad miss san diego</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>my boss is bullying me</td>\n",
              "      <td>2</td>\n",
              "      <td>boss bullying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>what interview leave me alone</td>\n",
              "      <td>2</td>\n",
              "      <td>interview leave alone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sons of  why couldnt they put them on the rel...</td>\n",
              "      <td>2</td>\n",
              "      <td>sons couldnt put releases already bought</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>some shameless plugging for the best rangers...</td>\n",
              "      <td>0</td>\n",
              "      <td>shameless plugging best rangers forum earth</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2am feedings for the baby are fun when he is a...</td>\n",
              "      <td>1</td>\n",
              "      <td>2am feedings baby fun smiles coos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>soooo high</td>\n",
              "      <td>0</td>\n",
              "      <td>soooo high</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>both of you</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>journey wow u just became cooler  hehe is tha...</td>\n",
              "      <td>1</td>\n",
              "      <td>journey wow u became cooler hehe possible</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  sentiment  \\\n",
              "0                  id have responded if i were going          0   \n",
              "1         sooo sad i will miss you here in san diego          2   \n",
              "2                             my boss is bullying me          2   \n",
              "3                      what interview leave me alone          2   \n",
              "4   sons of  why couldnt they put them on the rel...          2   \n",
              "5    some shameless plugging for the best rangers...          0   \n",
              "6  2am feedings for the baby are fun when he is a...          1   \n",
              "7                                         soooo high          0   \n",
              "8                                        both of you          0   \n",
              "9   journey wow u just became cooler  hehe is tha...          1   \n",
              "\n",
              "                           SentimentText_clean  \n",
              "0                           id responded going  \n",
              "1                      sooo sad miss san diego  \n",
              "2                                boss bullying  \n",
              "3                        interview leave alone  \n",
              "4     sons couldnt put releases already bought  \n",
              "5  shameless plugging best rangers forum earth  \n",
              "6            2am feedings baby fun smiles coos  \n",
              "7                                   soooo high  \n",
              "8                                               \n",
              "9    journey wow u became cooler hehe possible  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Import parquet file.\n",
        "\n",
        "tweets_df = pd.read_parquet('../../data/processed/tweets.parquet')\n",
        "\n",
        "# Show the head of the dataframe.\n",
        "\n",
        "tweets_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Dw3Rbo2zzuOo"
      },
      "outputs": [],
      "source": [
        "# Save in tweets the column \"SentimentText_clean\" and in sentimientos the column \"sentiment\".   \n",
        "\n",
        "tweets = tweets_df[\"SentimentText_clean\"]\n",
        "\n",
        "sentimientos = tweets_df[\"sentiment\"].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62j40yWBxBY3",
        "outputId": "ea0323ab-5773-43e5-8b1a-9c144622f8a4"
      },
      "outputs": [],
      "source": [
        "# Dividir los datos en características y etiquetas\n",
        "X = tweets\n",
        "y = tweets_df['sentiment'].values\n",
        "y = tf.keras.utils.to_categorical(y)  # Convertir los valores numéricos a representación categórica (one-hot encoding)\n",
        "\n",
        "# División de datos en conjunto de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenización y secuenciación del texto\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# Save the tokenizer.\n",
        "\n",
        "with open('../../models/tweets_tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# Ajuste de la longitud de las secuencias (padding)\n",
        "max_sequence_length = 100  # Longitud máxima de una secuencia de palabras\n",
        "X_train_seq = tf.keras.preprocessing.sequence.pad_sequences(X_train_seq, maxlen=max_sequence_length)\n",
        "X_test_seq = tf.keras.preprocessing.sequence.pad_sequences(X_test_seq, maxlen=max_sequence_length)\n",
        "\n",
        "# Creación del modelo de red neuronal\n",
        "model = models.Sequential()\n",
        "model.add(layers.Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100, input_length=max_sequence_length))\n",
        "model.add(layers.LSTM(64))\n",
        "model.add(layers.Dense(3, activation='softmax'))\n",
        "\n",
        "\n",
        "# Compilación del modelo\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "#model.fit(X_train_seq, y_train, validation_data=(X_test_seq, y_test), epochs=10, batch_size=32)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lh4fvQGrx4lz"
      },
      "outputs": [],
      "source": [
        "#model.save(\"../../models/nn_reviews.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 100)          2391000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                42240     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,433,435\n",
            "Trainable params: 2,433,435\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
          ]
        }
      ],
      "source": [
        "# Model structure\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Plot model structure\n",
        "\n",
        "tf.keras.utils.plot_model(model, to_file='nn_reviews.png', show_shapes=True, show_layer_names=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 835ms/step\n",
            "positivo\n"
          ]
        }
      ],
      "source": [
        "# Load the model.\n",
        "\n",
        "model = tf.keras.models.load_model('../../models/nn_tweets.h5', compile=False)\n",
        "\n",
        "with open('../../models/tweets_tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "max_sequence_length = 100\n",
        "\n",
        "# Prueba con un texto a introducir\n",
        "text_to_predict = \"I love pizza\"\n",
        "text_to_predict_seq = tokenizer.texts_to_sequences([text_to_predict])\n",
        "text_to_predict_seq = tf.keras.preprocessing.sequence.pad_sequences(text_to_predict_seq, maxlen=max_sequence_length)\n",
        "prediction = model.predict(text_to_predict_seq)\n",
        "sentiment_label = np.argmax(prediction)\n",
        "\n",
        "# Mapeo de la clase de sentimiento predicha a su etiqueta original (0: neutral, 1: positivo, 2: negativo)\n",
        "sentiment_labels = ['neutral', 'positivo', 'negativo']\n",
        "predicted_sentiment = sentiment_labels[sentiment_label]\n",
        "\n",
        "# Print the predicted sentiment.\n",
        "\n",
        "print(predicted_sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "172/172 [==============================] - 5s 26ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.6525390206829367"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# predict the test data.\n",
        "\n",
        "y_pred = model.predict(X_test_seq)\n",
        "\n",
        "# Calculate the fbeta score.\n",
        "\n",
        "fbeta_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), average='macro', beta=2)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
