{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"top\"> <h1>01. ML Models</h1> <a>\n",
    "\n",
    "<p>Análisis de sentimiento: Tweets<br />\n",
    "<strong>Trabajo de Fin de Master</strong><br />\n",
    "<strong>Master Universitario en Ciencia de Datos</strong></p>\n",
    "\n",
    "\n",
    "<p style=\"text-align:right\">V&iacute;ctor Viloria V&aacute;zquez (<em>victor.viloria@cunef.edu</em>)</p>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estructura"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Introducción](#introduccion) \n",
    "\n",
    "[1. Librerias utilizadas y funciones](#librerias) \n",
    "\n",
    "[2. Lectura del dataframe y preparación de los datos](#lectura) \n",
    "\n",
    "   - 2.1. Lectura del DF\n",
    "   - 2.2. Preparación de los datos\n",
    "\n",
    "[3. Evaluación de los modelos ](#modelos) \n",
    "\n",
    "   - 3.1. Support Vector Classifier\n",
    "   - 3.2. Multinomial Naive Bayes\n",
    "   - 3.3. Random Forest\n",
    "   - 3.4. Logistic Regression\n",
    "\n",
    "\n",
    "[4. Resultado de los modelos](#evaluacion) \n",
    "\n",
    "\n",
    "[5. Calibración del modelo](#calibracion)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"introduccion\"> Introducción <a>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este segundo notebook procederemos a desarrollar diferentes modelos de Machine Learning en base al dataframe que preprocesamos en `0_DataPreprocessing`.\n",
    "\n",
    "El objetivo será probar diferentes modelos de Machine Learning para poder clasificarlos según su rendimiento y observar si en función del texto, la puntuación asignada sería acorde a la del usuario.\n",
    "\n",
    "Para el desarrollo de estas tareas utilizaremos la librería de SKLearn, la cual dispone de diferentes modelos de clasificación que funcionan bastante bien. En particular, probaremos varios modelos, como el SVC (Support Vector Classification), el Multinomial Naive Bayes, Random Forest y Regresión Logística."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"librerias\"> 1. Librerias utilizadas y funciones <a>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las librerias a utilizar para la creación de modelos de ML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic libraries.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "# Import ML libraries.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Import libraries for evaluation.\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic libraries.\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle \n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Import sklearn metrics.\n",
    "\n",
    "from sklearn.metrics import  fbeta_score, roc_curve, classification_report,accuracy_score,roc_auc_score\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"lectura\"> 2. Lectura del dataframe y preparación de los datos<a>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Lectura del DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazon shopping amazoncom gift cards christmas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>got gift card friend best site much choose gre...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arent going save trees people complaining pape...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>always get someone something amazon safety net...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>take 50 dollars good money limitations turn am...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall\n",
       "0  amazon shopping amazoncom gift cards christmas...        1\n",
       "1  got gift card friend best site much choose gre...        5\n",
       "2  arent going save trees people complaining pape...        5\n",
       "3  always get someone something amazon safety net...        5\n",
       "4  take 50 dollars good money limitations turn am...        1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import parquet file.\n",
    "\n",
    "reviews = pd.read_parquet('../../data/processed/reviews.parquet')\n",
    "\n",
    "# Show the head of the dataframe.\n",
    "\n",
    "reviews.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Preparación de los datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparamos los datos para que puedan ser introducidos dentro de los modelos, separando en X el texto y en Y las puntuaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data into X and y.\n",
    "\n",
    "X = reviews.reviewText\n",
    "y = reviews.overall\n",
    "\n",
    "# Split into train and test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"modelos\"> 3. Evaluación de los modelos<a>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tfidf = TfidfVectorizer(stop_words=\"english\",max_df=0.99,min_df=0.01)\n",
    "svc = SVC(probability=True)\n",
    "model = make_pipeline(tfidf, svc)\n",
    "#Training\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "#Prediccion sobre test\n",
    "preds= model.predict(x_test)\n",
    "predict_probabilities = model.predict_proba(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.32      0.42      1420\n",
      "           2       1.00      0.00      0.01       316\n",
      "           3       0.00      0.00      0.00       597\n",
      "           4       0.00      0.00      0.00      1739\n",
      "           5       0.88      0.99      0.93     25367\n",
      "\n",
      "    accuracy                           0.87     29439\n",
      "   macro avg       0.50      0.26      0.27     29439\n",
      "weighted avg       0.80      0.87      0.82     29439\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vvict\\anaconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\vvict\\anaconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\vvict\\anaconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "\n",
    "# Use classification report to evaluate the model.\n",
    "\n",
    "classification_report = classification_report(y_test, preds)\n",
    "\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List with the titles and parameters\n",
    "\n",
    "titles_options = [(\"Confusion matrix, without normalization\", None),\n",
    "                  (\"Normalized confusion matrix\", 'true')]\n",
    "\n",
    "# Plot the confusion matrix\n",
    "\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(model, x_test, y_test,\n",
    "                                 # display_labels=ytest,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize=normalize)\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "739       perfect bridal shower perfect size weddings sh...\n",
       "51861     love gift cards little amazon boxes cute howev...\n",
       "85322     love pizza got great value lightning deal sale...\n",
       "56676                            nice got fast good quality\n",
       "47567     great gift loved ones live far away saves stam...\n",
       "                                ...                        \n",
       "41239     live country amazon gift cards way go gifts gi...\n",
       "55985     gift lifesaver holiday season great gift perso...\n",
       "32399     sure give someone give amazon gift card get wh...\n",
       "82584     birthday gift card perfect present kindle read...\n",
       "121909                                   much say gift card\n",
       "Name: reviewText, Length: 117755, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, ..., 5, 5, 5], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "predict_proba is not available when  probability=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mpredict_proba(x_test)\n",
      "File \u001b[1;32mc:\\Users\\vvict\\anaconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\utils\\_available_if.py:32\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor.__get__\u001b[1;34m(self, obj, owner)\u001b[0m\n\u001b[0;32m     26\u001b[0m attr_err \u001b[39m=\u001b[39m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[0;32m     27\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThis \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(owner\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m has no attribute \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattribute_name)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     29\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     30\u001b[0m     \u001b[39m# delegate only on instances, not the classes.\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     \u001b[39m# this is to allow access to the docstrings.\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck(obj):\n\u001b[0;32m     33\u001b[0m         \u001b[39mraise\u001b[39;00m attr_err\n\u001b[0;32m     34\u001b[0m     out \u001b[39m=\u001b[39m MethodType(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn, obj)\n",
      "File \u001b[1;32mc:\\Users\\vvict\\anaconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\pipeline.py:46\u001b[0m, in \u001b[0;36m_final_estimator_has.<locals>.check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     45\u001b[0m     \u001b[39m# raise original `AttributeError` if `attr` does not exist\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m     \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_final_estimator, attr)\n\u001b[0;32m     47\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vvict\\anaconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\utils\\_available_if.py:32\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor.__get__\u001b[1;34m(self, obj, owner)\u001b[0m\n\u001b[0;32m     26\u001b[0m attr_err \u001b[39m=\u001b[39m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[0;32m     27\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThis \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(owner\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m has no attribute \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattribute_name)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     29\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     30\u001b[0m     \u001b[39m# delegate only on instances, not the classes.\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     \u001b[39m# this is to allow access to the docstrings.\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck(obj):\n\u001b[0;32m     33\u001b[0m         \u001b[39mraise\u001b[39;00m attr_err\n\u001b[0;32m     34\u001b[0m     out \u001b[39m=\u001b[39m MethodType(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn, obj)\n",
      "File \u001b[1;32mc:\\Users\\vvict\\anaconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\svm\\_base.py:829\u001b[0m, in \u001b[0;36mBaseSVC._check_proba\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_proba\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    828\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprobability:\n\u001b[1;32m--> 829\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[0;32m    830\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mpredict_proba is not available when  probability=False\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m         )\n\u001b[0;32m    832\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_impl \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mc_svc\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnu_svc\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    833\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mpredict_proba only implemented for SVC and NuSVC\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: predict_proba is not available when  probability=False"
     ]
    }
   ],
   "source": [
    "model.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8723122388668093"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(preds==y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "clf = MultinomialNB()\n",
    "\n",
    "model = make_pipeline(tfidf, clf)\n",
    "#Training\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "#Prediccion sobre test\n",
    "preds= model.predict(x_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8631407316824621"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the accuracy.\n",
    "\n",
    "np.mean(preds==y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8662318692890384"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "model = make_pipeline(tfidf, rf)\n",
    "\n",
    "#Training\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "#Prediccion sobre test\n",
    "\n",
    "preds= model.predict(x_test )\n",
    "\n",
    "# Evaluate the model\n",
    "\n",
    "np.mean(preds==y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8713271510581202"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "model = make_pipeline(tfidf, lr)\n",
    "\n",
    "#Training\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "#Prediccion sobre test\n",
    "\n",
    "preds= model.predict(x_test )\n",
    "\n",
    "# Evaluate the model\n",
    "\n",
    "np.mean(preds==y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"evaluacion\"> 4. Resultado de los modelos <a>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos los restultados arrojados por los modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Accuracy\n",
       "0                     SVC     0.872\n",
       "1      LogisticRegression     0.871\n",
       "2  RandomForestClassifier     0.866\n",
       "3           MultinomialNB     0.863"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe with the results of each model.\n",
    "\n",
    "results = pd.DataFrame({'Model': ['SVC', 'MultinomialNB', 'RandomForestClassifier', 'LogisticRegression'], 'Accuracy': [0.872, 0.863, 0.866, 0.871]})\n",
    "\n",
    "# Show the results.\n",
    "\n",
    "results.sort_values(by='Accuracy', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"calibracion\"> 5. Calibración del modelo <a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune the hyperparameters of the SVC model.\n",
    "\n",
    "parameters = {'svc__C': [0.1, 1, 10], 'svc__gamma': [0.001, 0.01, 0.1]}\n",
    "grid = GridSearchCV(model, parameters, cv=5)\n",
    "grid.fit(x_train, y_train)\n",
    "\n",
    "# Show the best parameters.\n",
    "\n",
    "grid.best_params_\n",
    "\n",
    "# Show the best score.\n",
    "\n",
    "grid.best_score_\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
