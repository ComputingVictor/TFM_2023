{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "D1anb1ytuz2k"
      },
      "source": [
        "<a name=\"top\"> <h1>02. Neuronal Networks</h1> <a>\n",
        "\n",
        "<p>Análisis de sentimiento: Tweets<br />\n",
        "<strong>Trabajo de Fin de Master</strong><br />\n",
        "<strong>Master Universitario en Ciencia de Datos</strong></p>\n",
        "\n",
        "\n",
        "<p style=\"text-align:right\">V&iacute;ctor Viloria V&aacute;zquez (<em>victor.viloria@cunef.edu</em>)</p>\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MGnWP0EVuz2p"
      },
      "source": [
        "<hr style=\"border:1px solid gray\">"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "V-c-ExD8uz2y"
      },
      "source": [
        "### Estructura"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4y506okXuz22"
      },
      "source": [
        "[Introducción](#introduccion) \n",
        "\n",
        "[1. Librerias utilizadas y funciones](#librerias) \n",
        "\n",
        "[2. Lectura del dataframe y preparación de los datos](#lectura) \n",
        "\n",
        "   - 2.1. Lectura del DF\n",
        "   - 2.2. Preparación de los datos\n",
        "\n",
        "[3. Modelo de la red neuronal](#modelo) \n",
        "\n",
        "[4. Backup del modelo](#backup) "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nhcT10vJuz24"
      },
      "source": [
        "<hr style=\"border:1px solid gray\">"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a name=\"introduccion\"> Introducción <a>\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En este tercer notebook, tras haber preprocesado los datos y evaluado diferentes modelos de Machine Learning, exploraremos las redes neuronales con el objetivo de superar los resultados obtenidos en `1_MLModels`\n",
        "\n",
        "Para ello nos ayudaremos principalmente de la libreria TensorFlow, la cual nos permite de una forma secilla, crear arquitecutras de redes neuronales y modificar los hiperparámetros para ajustar el modelo, además de introducir técnicas de regularización.\n",
        "\n",
        "Una vez obtengamos los resultados y seleccionemos aquel que mejor resultado haya arrojado, procederemos a seleccionarlo ya sea de ML o DL, para ponerlo en producción."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_mjKoACXuz25"
      },
      "source": [
        "# <a name=\"librerias\"> 1. Librerias utilizadas y funciones <a>\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9JBx12Gsuz26"
      },
      "source": [
        "Importamos las librerias a utilizar para la creación de redes neuronales:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "a3eiEFg5uz3G"
      },
      "outputs": [],
      "source": [
        "# Import basic libraries.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "import numpy as np\n",
        "import string\n",
        "import pickle\n",
        "\n",
        "# Import neural network libraries.\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "U3CG8-gbuz3I"
      },
      "source": [
        "# <a name=\"lectura\"> 2. Lectura del dataframe y preparación de los datos<a>\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.1. Lectura del DF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PJBg5uE4uz3J",
        "outputId": "0b2e4e2e-c2af-4e74-9bbc-eb0920e4d506"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewText</th>\n",
              "      <th>overall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>amazon shopping amazoncom gift cards christmas...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>got gift card friend best site much choose gre...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>arent going save trees people complaining pape...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>always get someone something amazon safety net...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>take 50 dollars good money limitations turn am...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          reviewText  overall\n",
              "0  amazon shopping amazoncom gift cards christmas...        1\n",
              "1  got gift card friend best site much choose gre...        5\n",
              "2  arent going save trees people complaining pape...        5\n",
              "3  always get someone something amazon safety net...        5\n",
              "4  take 50 dollars good money limitations turn am...        1"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Import parquet file.\n",
        "\n",
        "reviews = pd.read_parquet('../../data/processed/reviews.parquet')\n",
        "\n",
        "# Show the head of the dataframe.\n",
        "\n",
        "reviews.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Dodel_Vsuz3T"
      },
      "source": [
        "## 2.2. Preparación de los datos"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Al igual que en el notebook anterior, preparamos los datos para que puedan ser introducidos dentro de los modelos, separando en X el texto y en y las puntuaciones. Y modificando el formato para que puedan ser introducidos dentro de la red."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qTJuSounuz3U"
      },
      "outputs": [],
      "source": [
        "# Define the X and y variables.\n",
        "\n",
        "X = reviews['reviewText'].values\n",
        "y = reviews['overall'].values\n",
        "\n",
        "# Modify the y variable to be a categorical variable.\n",
        "\n",
        "y = tf.keras.utils.to_categorical(y-1, num_classes=5)\n",
        "\n",
        "# Split the data into train and test sets.\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
        "\n",
        "# Define the tokenizer.\n",
        "\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "\n",
        "# Fit the tokenizer.\n",
        "\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# Transform the train and test sets.\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# Add padding to the train and test sets.\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "maxlen = 300\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the tokenizer in models.\n",
        "\n",
        "with open('../../models/tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a name=\"modelo\"> 3. Modelo de la red neuronal<a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tras hacer diferentes pruebas fuera del notebook, ponemos a prueba el que mejor resultado nos ha dado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Lhr1sHUYuz3j"
      },
      "outputs": [],
      "source": [
        "# Define the model.\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=10000, output_dim=128, input_length=300),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
        "    tf.keras.layers.LSTM(64),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model.\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wz2jlfUguz3m",
        "outputId": "1e1c145e-3803-44b9-ed32-3427d9443e31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "920/920 [==============================] - 550s 594ms/step - loss: 0.5846 - accuracy: 0.8596 - val_loss: 0.5708 - val_accuracy: 0.8617\n",
            "Epoch 2/10\n",
            "920/920 [==============================] - 567s 616ms/step - loss: 0.5747 - accuracy: 0.8604 - val_loss: 0.5695 - val_accuracy: 0.8617\n",
            "Epoch 3/10\n",
            "920/920 [==============================] - 598s 650ms/step - loss: 0.5746 - accuracy: 0.8605 - val_loss: 0.5693 - val_accuracy: 0.8617\n",
            "Epoch 4/10\n",
            "920/920 [==============================] - 720s 782ms/step - loss: 0.5745 - accuracy: 0.8604 - val_loss: 0.5694 - val_accuracy: 0.8617\n",
            "Epoch 5/10\n",
            "920/920 [==============================] - 562s 611ms/step - loss: 0.5745 - accuracy: 0.8605 - val_loss: 0.5708 - val_accuracy: 0.8617\n",
            "Epoch 6/10\n",
            "920/920 [==============================] - 568s 617ms/step - loss: 0.5743 - accuracy: 0.8605 - val_loss: 0.5701 - val_accuracy: 0.8617\n",
            "Epoch 7/10\n",
            "920/920 [==============================] - 560s 609ms/step - loss: 0.5764 - accuracy: 0.8600 - val_loss: 0.5697 - val_accuracy: 0.8617\n",
            "Epoch 8/10\n",
            "920/920 [==============================] - 566s 615ms/step - loss: 0.5743 - accuracy: 0.8605 - val_loss: 0.5694 - val_accuracy: 0.8617\n",
            "Epoch 9/10\n",
            "920/920 [==============================] - 643s 699ms/step - loss: 0.5742 - accuracy: 0.8605 - val_loss: 0.5694 - val_accuracy: 0.8617\n",
            "Epoch 10/10\n",
            "920/920 [==============================] - 554s 602ms/step - loss: 0.5743 - accuracy: 0.8605 - val_loss: 0.5692 - val_accuracy: 0.8617\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1af5c14d790>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Fit the model.\n",
        "\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=128)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a name=\"backup\"> 4. Backup del modelo<a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dado que es el modelo que mejor resultado nos ha dado, procedemos a guardarlo para posteriormente ponerlo en producción."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4QSIAZH9wU-p"
      },
      "outputs": [],
      "source": [
        "# Guardar el modelo en un archivo\n",
        "model.save(\"../../models/nn_reviews.h5\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "TFM",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
